{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree 圖解:\n",
    "\n",
    "https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-5%E8%AC%9B-%E6%B1%BA%E7%AD%96%E6%A8%B9-decision-tree-%E4%BB%A5%E5%8F%8A%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97-random-forest-%E4%BB%8B%E7%B4%B9-7079b0ddfbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "\n",
    "global divding_line\n",
    "dividing_line = '\\n==================================================\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   sepal_length(cm)  150 non-null    float64\n",
      " 1   sepal_width(cm)   150 non-null    float64\n",
      " 2   petal_length(cm)  150 non-null    float64\n",
      " 3   petal_width(cm)   150 non-null    float64\n",
      " 4   target            150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "iris_dataset = datasets.load_iris()\n",
    "\n",
    "x = pd.DataFrame(iris_dataset['data'], columns = iris_dataset['feature_names'])\n",
    "y = pd.DataFrame(iris_dataset['target'], columns = ['target'])\n",
    "\n",
    "y = y.replace([0, 1, 2], ['Iris-setosar', 'Iris-versicolor', 'Iris-virginica'])\n",
    "\n",
    "x = x.rename(columns = {'sepal length (cm)' : 'sepal_length(cm)', 'sepal width (cm)' : 'sepal_width(cm)'\n",
    "                   , 'petal length (cm)' : 'petal_length(cm)', 'petal width (cm)' : 'petal_width(cm)'})\n",
    "\n",
    "df = pd.concat([x, y], axis = 1)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length(cm)</th>\n",
       "      <th>sepal_width(cm)</th>\n",
       "      <th>petal_length(cm)</th>\n",
       "      <th>petal_width(cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length(cm)  sepal_width(cm)  petal_length(cm)  petal_width(cm)  \\\n",
       "0               5.1              3.5               1.4              0.2   \n",
       "1               4.9              3.0               1.4              0.2   \n",
       "2               4.7              3.2               1.3              0.2   \n",
       "3               4.6              3.1               1.5              0.2   \n",
       "4               5.0              3.6               1.4              0.2   \n",
       "5               5.4              3.9               1.7              0.4   \n",
       "6               4.6              3.4               1.4              0.3   \n",
       "7               5.0              3.4               1.5              0.2   \n",
       "8               4.4              2.9               1.4              0.2   \n",
       "9               4.9              3.1               1.5              0.1   \n",
       "\n",
       "         target  \n",
       "0  Iris-setosar  \n",
       "1  Iris-setosar  \n",
       "2  Iris-setosar  \n",
       "3  Iris-setosar  \n",
       "4  Iris-setosar  \n",
       "5  Iris-setosar  \n",
       "6  Iris-setosar  \n",
       "7  Iris-setosar  \n",
       "8  Iris-setosar  \n",
       "9  Iris-setosar  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length(cm)    0\n",
       "sepal_width(cm)     0\n",
       "petal_length(cm)    0\n",
       "petal_width(cm)     0\n",
       "target              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_to_train_test_set(dataFrame, portion_to_split = 0.2):\n",
    "    indices = dataFrame.index.tolist()\n",
    "    indices_test_dataset = random.sample(population = indices, k = int(portion_to_split * len(dataFrame)))\n",
    "    \n",
    "    test_dataset = dataFrame.iloc[indices_test_dataset]\n",
    "    train_dataset = dataFrame.drop(indices_test_dataset, axis = 0)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with len: 120, testing with len: 30\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "train_df, test_df = split_data_to_train_test_set(df, portion_to_split = 0.2)\n",
    "\n",
    "print('Training dataset with len: {}, testing with len: {}'.format(len(train_df), len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(array):\n",
    "    labels = array[:, -1]\n",
    "    unique_classes = np.unique(labels)\n",
    "    \n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5 2.5 4.0 1.3 'Iris-versicolor']\n",
      " [5.5 2.6 4.4 1.2 'Iris-versicolor']\n",
      " [5.8 2.6 4.0 1.2 'Iris-versicolor']\n",
      " [5.0 2.3 3.3 1.0 'Iris-versicolor']\n",
      " [5.6 2.7 4.2 1.3 'Iris-versicolor']\n",
      " [5.7 3.0 4.2 1.2 'Iris-versicolor']\n",
      " [5.7 2.9 4.2 1.3 'Iris-versicolor']\n",
      " [6.2 2.9 4.3 1.3 'Iris-versicolor']\n",
      " [5.7 2.8 4.1 1.3 'Iris-versicolor']\n",
      " [6.3 3.3 6.0 2.5 'Iris-virginica']\n",
      " [5.8 2.7 5.1 1.9 'Iris-virginica']\n",
      " [7.1 3.0 5.9 2.1 'Iris-virginica']\n",
      " [6.5 3.0 5.8 2.2 'Iris-virginica']\n",
      " [7.6 3.0 6.6 2.1 'Iris-virginica']\n",
      " [4.9 2.5 4.5 1.7 'Iris-virginica']\n",
      " [6.7 2.5 5.8 1.8 'Iris-virginica']\n",
      " [7.2 3.6 6.1 2.5 'Iris-virginica']\n",
      " [6.5 3.2 5.1 2.0 'Iris-virginica']\n",
      " [6.4 2.7 5.3 1.9 'Iris-virginica']\n",
      " [6.8 3.0 5.5 2.1 'Iris-virginica']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.values[70:90])\n",
    "\n",
    "check_purity(train_df.values[70:90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Iris-setosar', 'Iris-versicolor', 'Iris-virginica'], dtype=object),\n",
       " array([41, 38, 41], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_df.values[:, -1], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(array):\n",
    "    labels = array[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(labels, return_counts = True)\n",
    "    \n",
    "    index_max_counts = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index_max_counts]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-setosar'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(train_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    \n",
    "    for column_index in range(n_columns - 1):          # excluding the last column which is the label\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        type_of_feature = FEATURE_TYPES[column_index]\n",
    "        \n",
    "        if type_of_feature == \"continuous\":\n",
    "            potential_splits[column_index] = []\n",
    "            \n",
    "            for index in range(len(unique_values)):\n",
    "                if index != 0:\n",
    "                    current_value = unique_values[index]\n",
    "                    previous_value = unique_values[index - 1]\n",
    "                    potential_split = (current_value + previous_value) / 2\n",
    "\n",
    "                    potential_splits[column_index].append(potential_split)\n",
    "        \n",
    "        elif len(unique_values) > 1:\n",
    "            potential_splits[column_index] = unique_values\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(array, split_column, split_threshold):\n",
    "    split_column_values = array[:, split_column]\n",
    "    \n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    \n",
    "    if type_of_feature == 'continuous':\n",
    "        left_splited_data = array[split_column_values <= split_threshold]\n",
    "        right_splited_data = array[split_column_values > split_threshold]\n",
    "    else:\n",
    "        left_splited_data = array[split_column_values == split_threshold].copy()\n",
    "        right_splited_data = array[split_column_values != split_threshold].copy()\n",
    "    \n",
    "    return left_splited_data, right_splited_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不純度函數 --> 用來代表資訊量\n",
    "### 1. Entropy\n",
    "<img src=\"https://miro.medium.com/max/875/1*_otZEQ9iVAJirblwdVnIIw.png\" />\n",
    "\n",
    "### 2. Gini Impurity\n",
    "<img src=\"https://miro.medium.com/max/1225/1*WXHY6siVegJRKcFqxCRSYQ.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(array):\n",
    "    labels = array[:, -1]\n",
    "    \n",
    "    _, counts = np.unique(labels, return_counts = True)\n",
    "    \n",
    "    probabilities = counts / np.sum(counts)\n",
    "    \n",
    "    entropy = np.sum(-probabilities * np.log2(probabilities))\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini_impurity(array):\n",
    "    labels = array[:, -1]\n",
    "    \n",
    "    _, counts = np.unique(labels, return_counts = True)\n",
    "    \n",
    "    probabilities = counts / np.sum(counts)\n",
    "    \n",
    "    gini_impurity = 1 - np.sum(probabilities**2)\n",
    "    \n",
    "    return gini_impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5840530131956925\n"
     ]
    }
   ],
   "source": [
    "print(calculate_entropy(train_df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66625\n"
     ]
    }
   ],
   "source": [
    "print(calculate_gini_impurity(train_df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Iris-setosar', 'Iris-versicolor', 'Iris-virginica'], dtype=object),\n",
       " array([41, 38, 41], dtype=int64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_df.values[:, -1], return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## 信息增益 --> 用來挑選特徵\n",
    "<img src=\"https://miro.medium.com/max/875/1*FjGUfcYt_Vyupv1KfNm_pA.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_gain(criterion, left_splited_data, right_splited_data):\n",
    "    num_total_data = len(left_splited_data) + len(right_splited_data)\n",
    "    \n",
    "    prob_left_splited_data = len(left_splited_data) / num_total_data\n",
    "    prob_right_splited_data = len(right_splited_data) / num_total_data\n",
    "    \n",
    "    if criterion == 'entropy':\n",
    "        information_gain = (prob_left_splited_data * calculate_entropy(left_splited_data)) + (prob_right_splited_data * calculate_entropy(right_splited_data))\n",
    "    else:\n",
    "        information_gain = (prob_left_splited_data * calculate_gini_impurity(left_splited_data)) + (prob_right_splited_data * calculate_gini_impurity(right_splited_data))\n",
    "    \n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8542715202043386\n"
     ]
    }
   ],
   "source": [
    "print(calculate_information_gain('entropy', train_df.values[:50], train_df.values[50:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4060952380952381\n"
     ]
    }
   ],
   "source": [
    "print(calculate_information_gain('gini', train_df.values[:50], train_df.values[50:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_the_best_split(criterion, array, potential_splits):\n",
    "    min_information_gain = 9999999\n",
    "\n",
    "    for column_index, splits in potential_splits.items():\n",
    "        for threshold in splits:\n",
    "            left_splited_data, right_splited_data = split_dataset(array, column_index, threshold)\n",
    "            \n",
    "            if criterion == 'entropy':\n",
    "                current_information_gain = calculate_information_gain('entropy', left_splited_data, right_splited_data)\n",
    "            else:\n",
    "                current_information_gain = calculate_information_gain('gini', left_splited_data, right_splited_data)\n",
    "            \n",
    "            if current_information_gain <= min_information_gain:\n",
    "                min_information_gain = current_information_gain\n",
    "                best_split_column = column_index\n",
    "                best_threshold = threshold\n",
    "    \n",
    "    return best_split_column, best_threshold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_the_best_split('entropy', train_df.values, get_potential_splits(train_df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_the_best_split('gini', train_df.values, get_potential_splits(train_df.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the type of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    feature_types = []\n",
    "    n_unique_values_threshold = 15\n",
    "    \n",
    "    for feature in df.columns:\n",
    "        if feature != 'target':\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "            \n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_threshold):\n",
    "                feature_types.append('categorical')\n",
    "            else:\n",
    "                feature_types.append('continuous')\n",
    "    \n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_types_of_features(dataframe):\n",
    "    \n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 15\n",
    "    \n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sub_tree = {\"question\": [\"yes_answer\", \n",
    "                         \"no_answer\"]}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "樹的形式如下\n",
    "example_tree = {\"petal_width <= 0.8\": [\"Iris-setosa\", \n",
    "                                      {\"petal_width <= 1.65\": [{\"petal_length <= 4.9\": [\"Iris-versicolor\", \n",
    "                                                                                        \"Iris-virginica\"]}, \n",
    "                                                                \"Iris-virginica\"]}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_decision_tree_alogrithm(criterion, dataFrame, counter = 0, min_samples = 2, max_depth = 5):\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS = dataFrame.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(dataFrame)\n",
    "        data = dataFrame.values\n",
    "        \n",
    "    else:\n",
    "        data = dataFrame\n",
    "    \n",
    "    if (check_purity(data) or (len(data) < min_samples) or (counter == max_depth)):\n",
    "        classification = classify(data)\n",
    "        return classification\n",
    "    \n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "        potential_splits = get_potential_splits(data)\n",
    "        best_split_column, best_threshold = pick_the_best_split(criterion, data, potential_splits)\n",
    "        left_splited_data, right_splited_data = split_dataset(data, best_split_column, best_threshold)\n",
    "        \n",
    "        # determine the question for the decision tree node\n",
    "        feature_name = COLUMN_HEADERS[best_split_column]\n",
    "        type_of_feature = FEATURE_TYPES[best_split_column]\n",
    "        \n",
    "        if type_of_feature == \"continuous\":\n",
    "            split_strategy = \"{} <= {}\".format(feature_name, best_threshold)\n",
    "        else:\n",
    "            split_strategy = \"{} = {}\".format(feature_name, best_threshold)\n",
    "        \n",
    "        \n",
    "        root = {split_strategy : []}\n",
    "        \n",
    "        left_sub_tree = execute_decision_tree_alogrithm(criterion, left_splited_data, counter, min_samples, max_depth)\n",
    "        right_sub_tree = execute_decision_tree_alogrithm(criterion, right_splited_data, counter, min_samples, max_depth)\n",
    "        \n",
    "        root[split_strategy].append(left_sub_tree)\n",
    "        root[split_strategy].append(right_sub_tree)\n",
    "        \n",
    "        return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'petal_width(cm) <= 0.8': ['Iris-setosar',\n",
      "                            {'petal_width(cm) <= 1.65': [{'petal_length(cm) <= 4.95': ['Iris-versicolor',\n",
      "                                                                                       'Iris-virginica']},\n",
      "                                                         {'petal_length(cm) <= 4.85': ['Iris-virginica',\n",
      "                                                                                       'Iris-virginica']}]}]}\n"
     ]
    }
   ],
   "source": [
    "tree = execute_decision_tree_alogrithm('entropy', train_df, max_depth = 3)\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'petal_width(cm) <= 0.8': ['Iris-setosar',\n",
      "                            {'petal_width(cm) <= 1.65': [{'petal_length(cm) <= 4.95': ['Iris-versicolor',\n",
      "                                                                                       'Iris-virginica']},\n",
      "                                                         {'petal_length(cm) <= 4.85': ['Iris-virginica',\n",
      "                                                                                       'Iris-virginica']}]}]}\n"
     ]
    }
   ],
   "source": [
    "tree = execute_decision_tree_alogrithm('gini', train_df, max_depth = 3)\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_tree = {\"question\": [\"yes_answer\", \n",
    "                         \"no_answer\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length(cm)                5.1\n",
      "sepal_width(cm)                 2.5\n",
      "petal_length(cm)                  3\n",
      "petal_width(cm)                 1.1\n",
      "target              Iris-versicolor\n",
      "Name: 98, dtype: object\n"
     ]
    }
   ],
   "source": [
    "example = test_df.iloc[0]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_dataFrame(dataFrame, tree):\n",
    "    decision = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, threshold = decision.split()\n",
    "    \n",
    "    if comparison_operator == '<=':\n",
    "        if dataFrame[feature_name] <= float(threshold):\n",
    "            answer = tree[decision][0]\n",
    "        else:\n",
    "            answer = tree[decision][1]\n",
    "    else:\n",
    "        if str(dataFrame[feature_name]) == threshold:\n",
    "            answer = tree[decision][0]\n",
    "        else:\n",
    "            answer = tree[decision][1]\n",
    "    \n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_dataFrame(dataFrame, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-versicolor'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_dataFrame(example, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(dataFrame, tree):\n",
    "    dataFrame_copied = dataFrame.copy()\n",
    "    dataFrame_copied['classification'] = dataFrame_copied.apply(classify_dataFrame, axis = 1, args = (tree, ))\n",
    "    dataFrame_copied['classification_correct'] = dataFrame_copied['classification'].eq(dataFrame_copied['target'])\n",
    "    \n",
    "    accuaracy = dataFrame_copied['classification_correct'].mean()\n",
    "    \n",
    "    return accuaracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(test_df, tree)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv(\"./data/Titanic.csv\")\n",
    "df_titanic['target'] = df_titanic.Survived\n",
    "df_titanic = df_titanic.drop([\"PassengerId\", \"Survived\", \"Name\", \"Ticket\", \"Cabin\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Embarked      2\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_age = df_titanic.Age.median()\n",
    "mode_embarked = df_titanic.Embarked.mode()[0]\n",
    "\n",
    "df_titanic = df_titanic.fillna({'Age': median_age, 'Embarked' : mode_embarked})\n",
    "\n",
    "# df_titanic['Embarked'] = df_titanic['Embarked'].map({'Q' : 1, 'S' : 2, 'C' : 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['categorical',\n",
       " 'categorical',\n",
       " 'continuous',\n",
       " 'categorical',\n",
       " 'categorical',\n",
       " 'continuous',\n",
       " 'categorical']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determine_type_of_feature(df_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_data, right_data = split_dataset(df_titanic.values, split_column = 1, split_threshold = 'female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 'female', 38.0, ..., 71.2833, 'C', 1],\n",
       "       [3, 'female', 26.0, ..., 7.925, 'S', 1],\n",
       "       [1, 'female', 35.0, ..., 53.1, 'S', 1],\n",
       "       ...,\n",
       "       [3, 'female', 39.0, ..., 29.125, 'Q', 0],\n",
       "       [1, 'female', 19.0, ..., 30.0, 'S', 1],\n",
       "       [3, 'female', 28.0, ..., 23.45, 'S', 0]], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 'male', 22.0, ..., 7.25, 'S', 0],\n",
       "       [3, 'male', 35.0, ..., 8.05, 'S', 0],\n",
       "       [3, 'male', 28.0, ..., 8.4583, 'Q', 0],\n",
       "       ...,\n",
       "       [2, 'male', 27.0, ..., 13.0, 'S', 0],\n",
       "       [1, 'male', 26.0, ..., 30.0, 'C', 1],\n",
       "       [3, 'male', 32.0, ..., 7.75, 'Q', 0]], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sex = male': [{'Age <= 6.5': [{'SibSp = 4': [{'Fare <= 31.331249999999997': [0,\n",
      "                                                                               {'Fare <= 35.5375': [1,\n",
      "                                                                                                    0]}]},\n",
      "                                               {'SibSp = 5': [0,\n",
      "                                                              {'SibSp = 3': [0,\n",
      "                                                                             1]}]}]},\n",
      "                                {'Fare <= 26.26875': [{'Age <= 13.5': [{'Embarked = S': [1,\n",
      "                                                                                         0]},\n",
      "                                                                       {'Age <= 34.25': [0,\n",
      "                                                                                         0]}]},\n",
      "                                                      {'Fare <= 26.46875': [1,\n",
      "                                                                            {'Parch = 0': [0,\n",
      "                                                                                           0]}]}]}]},\n",
      "                {'Pclass = 3': [{'Fare <= 23.7': [{'Age <= 36.5': [{'Age <= 16.5': [1,\n",
      "                                                                                    1]},\n",
      "                                                                   0]},\n",
      "                                                  {'Parch = 0': [1,\n",
      "                                                                 {'Age <= 7.0': [0,\n",
      "                                                                                 0]}]}]},\n",
      "                                {'Fare <= 29.35625': [{'Fare <= 28.23125': [{'Age <= 56.0': [1,\n",
      "                                                                                             0]},\n",
      "                                                                            0]},\n",
      "                                                      1]}]}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7921348314606742"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "df_titanic_train, df_titanic_test = split_data_to_train_test_set(df_titanic, 0.2)\n",
    "tree = execute_decision_tree_alogrithm('gini', df_titanic_train, max_depth = 5)\n",
    "accuracy = calculate_accuracy(df_titanic_test, tree)\n",
    "\n",
    "pprint(tree, width = 10)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
